# Base configuration for Task 3 Enhanced DQN
experiment:
  name: "rainbow_dqn_base"
  description: "Base Rainbow DQN configuration for Task 3"
  student_id: "YOUR_STUDENT_ID"  # 請修改為你的學號
  tags: ["task3", "rainbow", "base"]

# Model architecture
model:
  architecture: "rainbow_dueling_dqn"
  input_channels: 4
  num_actions: 6
  hidden_dim: 512
  dueling: true
  noisy_nets: false
  distributional: false  # C51, 可選功能

# Training parameters
training:
  total_steps: 1000000
  batch_size: 32
  lr: 2.5e-4
  gamma: 0.99
  n_step: 3
  target_update_freq: 8000
  train_frequency: 4
  gradient_clipping: 10.0
  
  # Adam optimizer settings
  optimizer:
    type: "Adam"
    eps: 1.5e-4
    weight_decay: 0

# Exploration strategy
exploration:
  epsilon_start: 1.0
  epsilon_final: 0.01
  epsilon_decay_steps: 250000
  epsilon_eval: 0.001

# Prioritized Experience Replay
per:
  enabled: true
  alpha: 0.6
  beta_start: 0.4
  beta_final: 1.0
  beta_steps: 1000000
  buffer_size: 400000
  min_priority: 0.000001

# Double DQN
double_dqn:
  enabled: true

# Multi-step learning
multi_step:
  enabled: true
  n_step: 3

# Environment settings
environment:
  name: "ALE/Pong-v5"
  frame_stack: 4
  max_episode_steps: 108000
  
# Evaluation
evaluation:
  eval_frequency: 20000
  eval_episodes: 20
  eval_epsilon: 0.001
  save_videos: true
  video_episodes: 3

# Logging and monitoring
logging:
  log_frequency: 1000
  checkpoint_frequency: 10000
  milestone_steps: [200000, 400000, 600000, 800000, 1000000]
  
  # Weights & Biases
  wandb_enabled: true
  wandb_project: "DLP-Lab5-Task3-Enhanced-DQN"
  wandb_group: "task3_experiments"
  
  # Metrics to track
  metrics:
    performance: ["eval_score_mean", "eval_score_std", "best_score", "sample_efficiency"]
    training: ["loss", "q_value_mean", "q_value_std", "td_error_mean", "gradient_norm"]
    exploration: ["epsilon", "action_entropy"]
    system: ["fps", "gpu_util", "memory_usage", "replay_buffer_size"]
    algorithm: ["per_beta", "priority_mean", "importance_weight_mean", "n_step_reward_mean"]

# Hardware and performance
hardware:
  device: "cuda:0"
  mixed_precision: false
  compile_model: false
  num_workers: 4
  pin_memory: true

# Reproducibility
seed: 42
deterministic: false

# Early stopping
early_stopping:
  enabled: true
  target_score: 19.0
  patience_episodes: 100
  min_episodes: 1000